import shopify
from langchain.chains import ConversationalRetrievalChain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores.chroma import Chroma
from langchain_community.document_loaders import AirbyteShopifyLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_openai.embeddings import OpenAIEmbeddings
from prompt import get_prompt
from datetime import datetime
from zoneinfo import ZoneInfo
import os
from dotenv import load_dotenv, find_dotenv

load_dotenv(find_dotenv())


def get_chroma_client():
    """
    Returns a chroma vector store instance.

    Returns:
        langchain.vectorstores.chroma.Chroma: ChromaDB vector store instance.
    """
    embedding_function = OpenAIEmbeddings()
    return Chroma(
        collection_name="lifeinlilac_data",
        embedding_function=embedding_function,
        persist_directory="data/chroma",
    )


# Configuration for AirbyteShopifyLoader
config = {
    "start_date": "2024-02-15",
    "shop": "preordermagicapp.myshopify.com",
    "credentials": {
        "auth_method": "oauth2.0",
        "access_token": "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",
    },
}

data_file_path = "file::memory:?cache=shared"
# get all data again only if the data is updated
TOKEN = "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"
STORE_URL = "preordermagicapp.myshopify.com"  # Use just the domain
API_VERSION = "2023-01"
session = shopify.Session(STORE_URL, API_VERSION, TOKEN)
shopify.ShopifyResource.activate_session(session)


def delete_existing_data_file(file_path):
    if os.path.exists(file_path):
        os.remove(file_path)
        print(f"Deleted the existing file: {file_path}")
    else:
        print("No existing file to delete.")


# Delete the existing data file before starting the load process
delete_existing_data_file(data_file_path)

# Initialize loader with stream names
loader = AirbyteShopifyLoader(
    config=config, stream_name=["customers", "orders", "products"]
)
# Store the last state safely
last_state = loader.last_state

# Fetch and preprocess data
streams = ["customers", "orders", "products"]
all_data = []

for stream in streams:
    incremental_loader = AirbyteShopifyLoader(
        config=config, stream_name=stream, state=last_state
    )

    stream_data = incremental_loader.load()
    # print(stream_data[:5])
    item_length = len(stream_data)

    print(f"Loaded {len(stream_data)} records from {stream}")
    all_data.extend(stream_data)

# print(all_data[:5])
splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=100,
)

splits = splitter.split_text(str(all_data))
print(f"Splitted full text into {len(splits)} chunks")


class Document:
    def __init__(self, dictionary):
        self.__dict__ = dictionary


def make_chain():
    """
    Creates a chain of langchain components.

    Returns:
        langchain.chains.ConversationalRetrievalChain: ConversationalRetrievalChain instance.
    """
    model = ChatOpenAI(model_name="gpt-4-0125-preview", temperature=0.0, verbose=True)
    vector_store = get_chroma_client()
    documents = [{"page_content": split, "metadata": ""} for split in splits]
    document_objects = [Document(doc) for doc in documents]

    print(document_objects[0])
    vector_store.add_documents(document_objects, verbose=True)

    retriever = vector_store.as_retriever(search_type="mmr", verbose=True)
    prompt = get_prompt()
    chain = ConversationalRetrievalChain.from_llm(
        model,
        retriever=retriever,
        return_source_documents=True,
        combine_docs_chain_kwargs=dict(prompt=prompt),
        verbose=True,
        rephrase_question=False,
        # memory=ConversationBufferWindowMemory(k=10),
    )
    return chain


current_time = datetime.now(ZoneInfo("America/Chicago"))
hour = current_time.hour
part_of_day = None
if 5 <= hour < 12:
    part_of_day = "Good morning"
elif 12 <= hour < 17:
    part_of_day = "Good afternoon"
else:
    part_of_day = "Good evening"

import datetime

# Get the current date and time
now = datetime.datetime.now()

# Format the date to get the full weekday name
day_of_week = now.strftime("%A")

print(day_of_week)


def get_response(question, name, email, thread_id, chat_history):
    """
    Generates a response based on the input question.

    Args:
        question (str): The input question to generate a response for.
        user (str): The name of the user.
        part_of_day (str): Part of the day (e.g., morning, afternoon, evening).
        chat_history (list): The chat history to be used and updated.

    Returns:
        str: The response generated by the chain model.
    """
    email = email
    thread_id = thread_id
    chain = make_chain()
    response = chain.invoke(
        {
            "question": question,
            "chat_history": chat_history,
            "name": name,
            "part_of_day": part_of_day,
            "day_of_week": day_of_week,
        }
    )

    return response["answer"]
